---
title: "CALIDAD DE AIRE"
author:
  - María Paula Camargo Rincón
  - Laura Katherin Martinez Castiblanco
  - Yudy Vanessa Puerres Rosero
date: "2025-10-20"
output: pdf_document
---
```{r}
rm(list=ls())
```


# librerías
```{r}
#install.packages("readxl")
#install.packages("knitr")
#install.packages("forecast")
#install.packages("FinTS")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("lubridate")
#install.packages("zoo")
#install.packages("nortest")
library(readxl) # Para leer el csv
library(knitr) # Para obtener la tabla en el pdf a partir de una tabla en r
library(forecast) # para el lambda de box-cox
library(tseries) # prueba de estacionariedad adf
library(FinTS)
library(dplyr) # para manejo de datos
library(ggplot2) # para gráficas
library(lubridate) # fechas
library(zoo) #imputación de datos faltantes
library(nortest) # para prueba kolmogorov
```

# Descripción de los datos:

## Base de datos

La base de datos utilizada proviene del conjunto de datos público disponible en la plataforma Kaggle ([Rohan Rao, 2020 ](https://www.kaggle.com/datasets/rohanrao/air-quality-data-in-india)). Este conjunto fue recopilado originalmente por el Central Pollution Control Board (CPCB**)**, organismo oficial del Gobierno de la India encargado del monitoreo ambiental.

Para este estudio, se utilizó la versión diaria del conjunto de datos, enfocándose exclusivamente en la variable PM2.5 (µg/m³) (partículas en suspensión con diámetro aerodinámico $\leq$ 2.5 µm) registrada en la ciudad de Delhi. La serie abarca el período comprendido entre el 1 de enero de 2015 y el 6 de diciembre de 2020, con observaciones diarias.
```{r}
aire <- read_excel("Datos_India.xlsx")
knitr::kable(head(aire,10),
             caption = "Primeros 10 datos",
             digits = 4)  # redondea a 4 decimales
```
Además de PM2.5, el conjunto incluye el Índice de Calidad del Aire (AQI) y su clasificación categórica (*AQI_Bucket*), que divide la calidad del aire en seis niveles: *Good*, *Satisfactory*, *Moderate*, *Poor*, *Very Poor* y *Severe*. Sin embargo, dado que el objetivo del análisis es modelar la dinámica temporal de la concentración de PM2.5, se trabajó únicamente con la variable numérica continua.

```{r}
# Convert 'City' and 'AQI_Bucket' to factor variables
aire$City <- as.factor(aire$City)
aire$AQI_Bucket <- as.factor(aire$AQI_Bucket)

# Convert 'Date' to a date variable, specifying the format
aire$Date <- as.Date(aire$Date, format = "%d/%m/%Y")

summary(aire)

str(aire)
```
## Evaluación de base de datos
```{r}
# Group by Date and count the number of entries
daily_counts <- aire %>%
  group_by(Date) %>%
  summarise(count = n())

# Filter for dates with more than one entry
dates_with_duplicates <- daily_counts %>%
  filter(count > 1)


# Display the dates with duplicate entries
if (nrow(dates_with_duplicates) > 0) {
  cat("Días con mas de un valor de  PM2.5:\n")
  print(dates_with_duplicates)
} else {
  cat("No hay días con mas de un valor de PM2.5\n")
}
```
El conjunto inicial contiene 2,009 observaciones. Se identificaron 2 valores faltantes en la variable `PM2.5` y 10 en `AQI_Bucket`. Dado que el AQI no se utilizará en el modelado, se centró la atención en imputar los valores ausentes de PM2.5. Se aplicó interpolación lineal mediante la función `na.approx()` del paquete `zoo`, asumiendo que la evolución de la contaminación en el corto plazo no es drástica.

```{r}
aire[!complete.cases(aire), ]
# Usar interpolación lineal para rellenar valores faltantes en 'PM2.5'
# Podemos usar la función na.approx del paquete zoo para la interpolación lineal.
aire$`PM2.5` <- na.approx(aire$`PM2.5`)

# Verificar que no haya más valores faltantes en 'PM2.5'
missing_pm25_after_imputation <- sum(is.na(aire$`PM2.5`))
cat("Número de datos faltantes en 'PM2.5' después de la imputación:", missing_pm25_after_imputation, "\n")
```
Las estadísticas resumen de la serie de PM2.5 revelan una distribución altamente asimétrica hacia la derecha, con una media de 117.10 µg/m³, una mediana de 94.49 µg/m³ y un máximo extremo de 685.36 µg/m³.

```{r}
# Estadísticas descriptivas
summary_stats <- aire %>%
  summarise(
    Media = mean(PM2.5, na.rm = TRUE),
    Mediana = median(PM2.5, na.rm = TRUE),
    Desv_Est = sd(PM2.5, na.rm = TRUE),
    Min = min(PM2.5, na.rm = TRUE),
    Max = max(PM2.5, na.rm = TRUE)
  )

kable(summary_stats, digits = 3, caption = "Estadísticas descriptivas de PM2.5 ")
```

La gráfica de la serie de tiempo muestra una variabilidad, con estacionalidad clara (patrones repetidos, que parecieran ser anuales). Aunque no se observa una tendencia, la varianza no es constante puesto que los picos son más pronunciados en ciertos períodos del año, lo que sugiere heterocedasticidad.

```{r}
# Creación de la serie
start_date <- min(aire$Date)
end_date <- max(aire$Date)
PM2.5 <- ts(aire$`PM2.5`, start = c(year(start_date), month(start_date), day(start_date)), end = c(year(end_date), month(end_date), day(end_date)), frequency = 365)

# Gráfica
ts.plot(PM2.5, col = "darkcyan", lwd = 2,
        ylab = "PM2.5 promedio diario", xlab = "Tiempo",
        main = "Serie de tiempo de PM2.5 (diaria)")

```
```{r}
par(mfrow=c(1,2))
acf(PM2.5) # decaimiento lento indica que la serie no es estacionaria
pacf(PM2.5)
```
Para evaluar formalmente la estacionariedad en media (la cual segun gráficos parece ser estacionaria), se usa la prueba de Dickey-Fuller (ADF). El estadístico resultante fue -4.7414 con un p-valor < 0.01, lo que permite rechazar la hipótesis nula de raíz unitaria. Por lo tanto, la serie se considera estacionaria.

```{r}
adf_result <- adf.test(PM2.5, alternative = "stationary")
cat("Prueba ADF:\n Estadístico =", round(adf_result$statistic, 4),
    ", p-valor =", adf_result$p.value, "\n")
```
Dada la heterocedasticidad, se evaluo una transformación para estabilizar la varianza. Se estimó el parámetro de Box-Cox, obteniéndo $\lambda$ $\approx$ 0.257, cercano a cero. Por lo cual se aplicó la transformación logarítmica.

```{r}
lambda <- BoxCox.lambda(PM2.5)
lambda

```

Dada la heterocedasticidad, se evaluo una transformación para
estabilizar la varianza. Se estimó el parámetro de Box-Cox, obteniéndo $\lambda$
= 0.257 ( cercana a 0). Por lo cual se aplicó la transformación
logarítmica.

```{r}
# Transformación logarítmica
l.PM2.5 <- log(PM2.5)
ts.plot(l.PM2.5, col = "darkblue",
        ylab = "log(PM2.5 promedio diario)",
        main = "Serie transformada logarítmicamente")

```
La serie transformada presenta una varianza más homogénea y mantiene la estacionariedad en media (prueba ADF con p-valor $\approx$ 0.027), cumpliendo así los supuestos de estacionariedad para el ajuste de modelos ARIMA.

```{r}
adf.test(l.PM2.5,alternative = "stationary")
```

Luego de aplicar la transformación logarítmica a la serie de PM2.5, el test de Dickey–Fuller Aumentado (ADF) arrojó un estadístico de -3.65 con un p-valor de 0.027, lo que indicaría estacionariedad a un nivel de significancia del 5%.
Sin embargo, la inspección de la función de autocorrelación (ACF) revela un decaimiento lento, señal de persistencia temporal y posible estacionalidad anual.
Por tanto, la serie log-transformada aún no puede considerarse estrictamente estacionaria, y se recomienda aplicar una diferenciación regular (d = 1)

```{r}
d.l.PM2.5 <- diff(l.PM2.5) # Retorno de PM2.5
ts.plot(d.l.PM2.5, col = "darkcyan", lwd = 1.25,
        ylab = " difflog(PM2.5 promedio diario)", xlab = "Tiempo",
        main = "Serie con diff de la transformación logaritmo")
adf.test(d.l.PM2.5)
par(mfrow=c(1,2))
acf(d.l.PM2.5)
pacf(d.l.PM2.5)

```
Luego de aplicar la transformación logarítmica, se realizó una diferenciación de primer orden (difflog(PM2.5)) con el fin de eliminar la tendencia presente en la serie.
La inspección de la serie transformada muestra oscilaciones alrededor de una media constante, sin tendencias visibles.
El test de Dickey–Fuller Aumentado (ADF) arrojó un estadístico de -16.31 con un p-valor < 0.01, indicando que la serie diferenciada es estacionaria.
Asimismo, la función de autocorrelación (ACF) se corta rápidamente tras el primer rezago, confirmando la ausencia de dependencia de largo plazo.
En consecuencia, la serie transformada y diferenciada cumple los supuestos de estacionariedad necesarios para proceder con la identificación de un modelo ARIMA.

Luego de aplicar la transformación logarítmica, se realizó una
diferenciación de primer orden ($\Delta \log$(PM2.5)) con el fin de
eliminar la tendencia presente en la serie. La inspección de la serie
transformada muestra oscilaciones alrededor de una media constante, sin
tendencias visibles. El test de Dickey–Fuller Aumentado (ADF) arrojó un
estadístico de -16.31 con un p-valor \< 0.01, indicando que la serie
diferenciada es estacionaria. Asimismo, la función de autocorrelación
(ACF) se corta rápidamente tras el primer rezago, confirmando la
ausencia de dependencia de largo plazo. En consecuencia, la serie
transformada y diferenciada cumple los supuestos de estacionariedad
necesarios para proceder con la identificación de un modelo ARIMA.

# **Identificación de modelos ARIMA**

Se presentan estos 2 modelos el primero para la serie transformada con
$\log$ dado que, según el PACF (Función de Autocorrelación Parcial) de
esta, se observa que el último rezago significativo es 2 (lo que sugiere
un AR(1) o AR(2)). Por otro lado, con el ACF (Función de
Autocorrelación) de la serie se observa un decaimiento lento, por lo que
no se puede definir con certeza cuál sería la estructura de MA (Media
Móvil). Por ello, se prueba el ARMA(2,2) ( sugerido por la función
`auto.arima(log(PM2.5))`), el otro modelo
es un modelo ARIMA(1,1,2) (a su vez sugerido por
`auto.arima(Δlog(PM2.5))`). Adicinalmente se prueba un modelo ARIMA(2,1,2) puesto que se puede comparar la serie sin diferenciar propuesta con la misma pero diferenciandola.

```{r}
auto.arima(l.PM2.5, seasonal = FALSE)

arma2.2 <- arima(x = l.PM2.5,order = c(2,0,2))


auto.arima(d.l.PM2.5, seasonal = FALSE)

arima1.1.2 <- arima(x = l.PM2.5,order = c(1,1,2))

arima2.1.2 <- arima(x = l.PM2.5, order = c(2, 1, 2))
```

Dado que no se asume normalidad de los residuos, los criterios de información (AIC, BIC) (basados en la verosimilitud) no son tan confiables. Por ello, comparamos los modelos con medidas del error en la muestra de entrenamiento, que no dependen de supuestos distribucionales.


```{r}
# Obtener métricas de error en la muestra de entrenamiento
acc_arma2.2    <- accuracy(arma2.2)
acc_arima2.1.2 <- accuracy(arima2.1.2)
acc_arima2.1.2 <- accuracy(arima2.1.2)

# Crear tabla comparativa
comparacion <- data.frame(
  Modelo = c("ARMA(2,2)", "ARIMA(1,1,2)", "ARIMA(2,1,2)"),
  RMSE = c(acc_arma2.2[1, "RMSE"],
           acc_arima2.1.2[1, "RMSE"],
           acc_arima2.1.2[1, "RMSE"]),
  MAE  = c(acc_arma2.2[1, "MAE"],
           acc_arima2.1.2[1, "MAE"],
           acc_arima2.1.2[1, "MAE"]),
  MAPE = c(acc_arma2.2[1, "MAPE"],
           acc_arima2.1.2[1, "MAPE"],
           acc_arima2.1.2[1, "MAPE"])
)


# Mostrar tabla
knitr::kable(comparacion,
             caption = "Comparación de métricas de error en la muestra de entrenamiento",
             digits = 4,
             row.names = FALSE)
```           



Se observa que el ARMA(2,2) es el modelo que tiene el mejor ajuste en
terminos del error, seguido por el modelo ARIMA (2,1,2) a diferencia de
lo sugerido por la función `auto.arima()` , por lo que se prefiere
trabajar con estos dos modelos en adelante.

```{r}

# Nombres de parámetros (8 filas)
parametros <- c("Intercepto", "ar1", "ar2", "ma1", "ma2", "logLik", "AIC", "BIC")

# --- Modelo ARMA(2,2) ---
coef_arma <- coef(arma2.2)  # Tiene: ar1, ar2, ma1, ma2, intercept
# Aseguramos el orden: intercept, ar1, ar2, ma1, ma2
coef_arma_ordenado <- c(
  coef_arma["intercept"],
  coef_arma["ar1"],
  coef_arma["ar2"],
  coef_arma["ma1"],
  coef_arma["ma2"]
)
t_arma_ordenado <- coef_arma_ordenado / c(
  sqrt(arma2.2$var.coef["intercept", "intercept"]),
  sqrt(arma2.2$var.coef["ar1", "ar1"]),
  sqrt(arma2.2$var.coef["ar2", "ar2"]),
  sqrt(arma2.2$var.coef["ma1", "ma1"]),
  sqrt(arma2.2$var.coef["ma2", "ma2"])
)

# --- Modelo ARIMA(2,1,2) ---
# Este modelo NO tiene intercepto (porque d = 1), pero SÍ tiene ar1 y ar2
coef_arima212 <- coef(arima2.1.2)  # Debe tener: ar1, ar2, ma1, ma2
coef_arima212_ordenado <- c(
  NA,  # Intercepto
  coef_arima212["ar1"],
  coef_arima212["ar2"],
  coef_arima212["ma1"],
  coef_arima212["ma2"]
)

# Valores t para ARIMA(2,1,2)
t_arima212_ordenado <- c(
  NA,
  coef_arima212["ar1"] / sqrt(arima2.1.2$var.coef["ar1", "ar1"]),
  coef_arima212["ar2"] / sqrt(arima2.1.2$var.coef["ar2", "ar2"]),
  coef_arima212["ma1"] / sqrt(arima2.1.2$var.coef["ma1", "ma1"]),
  coef_arima212["ma2"] / sqrt(arima2.1.2$var.coef["ma2", "ma2"])
)

# --- Construir tabla ---
resumen <- data.frame(
  Parámetro = parametros,
  
  "ARMA(2,2)" = c(coef_arma_ordenado, arma2.2$loglik, arma2.2$aic, BIC(arma2.2)),
  "t-valor ARMA(2,2)" = c(t_arma_ordenado, NA, NA, NA),
  
  "ARIMA(2,1,2)" = c(coef_arima212_ordenado, arima2.1.2$loglik, arima2.1.2$aic, BIC(arima2.1.2)),
  "t-valor ARIMA(2,1,2)" = c(t_arima212_ordenado, NA, NA, NA),
  stringsAsFactors = FALSE
)

knitr::kable(
  resumen,
  caption = "Tabla de resumen de los modelos ARMA(2,2) y ARIMA(2,1,2)",
  digits = 3,
  row.names = FALSE
)
```

Se presentan a continuación las formulas de los modelos con los
coeficientes estimados de la serie transformada $\log(\text{PM}_{2.5})$,
denotada como $Z_t$:.

-   *Formula ARMA(2,2)*

$$
Z_t = \mu + \phi_1 Z_{t-1} + \phi_2 Z_{t-2} + a_t + \theta_1 a_{t-1} + \theta_2 a_{t-2} $$
$$ = 4.593 + 1.38 Z_{t-1} -0.388 Z_{t-2} + a_t + \theta_1 a_{t-1} + \theta_2 a_{t-2}$$

- *Formula ARIMA(1,1,2)*

$$\triangledown Z_{t}=0.216Z_{t-1}+a_{t}-0.428a_{t-1}-0.381a_{t-2}$$

- *Formula ARIMA(2,1,2)*

$$\triangledown Z_{t}=0.216Z_{t-1}+0.134Z_{t-2}+a_{t}-0.428a_{t-1}-0.381a_{t-2}$$

Se presentan a continuación las formulas de los modelos con las estimaciones de los coeficientes significativos:

- *Formula ARMA(2,2)*

$$Z_{t}=4.593Z_{t-1}-0.388Z_{t-2}+a_{t}-0.595a_{t-1}-0.209a_{t-2}+4.593$$
- *Formula ARIMA(1,1,2)*

$$\triangledown Z_{t}=0.216Z_{t-1}+a_{t}-0.428a_{t-1}-0.381a_{t-2}$$


- *Formula ARIMA(2,1,2)*

$$\triangledown Z_{t}=0.216Z_{t-1}+a_{t}-0.428a_{t-1}-0.381a_{t-2}$$

Para el modelo ARIMA(2,1,2) parece "reducirce" al modelo ARIMA(1,1,2)
# Validación modelos
## ARMA(2,2)
```{r}
par(mfrow = c(1, 2))
acf(l.PM2.5, main = "ACF empírica")
plotArmaTrueacf(list(ar = arma2.2$coef["ar2"]), main = "ACF teórica ARMA(2,2)")

pacf(l.PM2.5, main = "PACF empírica")
plotArmaTrueacf(list(ar = arma2.2$coef["ar2"]), pacf = TRUE, main = "PACF teórica ARMA(2,2)")
```

```{r}
par(mfrow=c(1,2))
acf(arma2.2$residuals)

pacf(arma2.2$residuals)
```
Los residuales del modelo ARMA(2,2) parecen comportarse como un ruido blanco, aunque se ve un rezago en el PACF, este se encuentra muy lejos de los primeros, por lo que no se toma tanta importancia 

```{r}
qqnorm(arma2.2$residuals)
qqline(arma2.2$residuals)
```
Los residuales aunque en su mayoría se encuentran alrededor de la línea, parece ser que se alejan mucho en las colas, lo que podría indicar no normalidad.
```{r}
Box.test(arma2.2$residuals)

tsdiag(arma2.2)
```
La prueba de Ljung box muestras que los residuales son independientes ya que su p-valor aproximadamente de 0.84, mayor al nivel de significanvia 5%, no se rechaza la hipotesis nula la cual indica independencia.
```{r}
ks.test(arma2.2$residuals, "pnorm", mean = 0, sd = sd(arma2.2$residuals))
shapiro.test(arma2.2$residuals)
```
Respecto a la normalidad, el p-valor fue menor al nivel de significancia por lo que se rechaza la hipotesis nula de que los residuales provienen de una distribución normal.
## ARIMA(2,1,2)
```{r}
par(mfrow = c(1, 2))
acf(d.l.PM2.5, main = "ACF empírica")
plotArmaTrueacf(list(ar = arima2.1.2$coef["ar2"]), main = "ACF teórica ARiMA(2,1,2)")

pacf(d.l.PM2.5, main = "PACF empírica")
plotArmaTrueacf(list(ar = arima2.1.2$coef["ar2"]), pacf = TRUE, main = "PACF teórica ARIMA(2,1,2)")
```
```{r}
par(mfrow=c(1,2))
acf(arima2.1.2$residuals)
pacf(arima2.1.2$residuals)
```
Los residuales del modelo ARIMA(2,1,2), al igual que con el anterior, parecen comportarse como un ruido blanco, e incluso tambien presentan un rezago en el PACF, con el mismo comportamiento del anterior, al ser tan lejano de los primeros valores, no se lo toma importancia.

```{r}
Box.test(arima2.1.2$residuals)

tsdiag(arima2.1.2)
```
La prueba de Ljung box muestras que los residuales son independientes ya que su p-valor aproximadamente de 0.95, mayor al nivel de significanvia 5%, por lo que no se rechaza la hipotesis nula la cual indica independencia.
```{r}
qqnorm(arima2.1.2$residuals)
qqline(arima2.1.2$residuals)
```
Al gual que con el modelo ARMA(2,2) parece haber problemas de normalidad ya que los datos suelen alejarse de la línea en las colas.
```{r}
ks.test(arma2.2$residuals, "pnorm", mean = 0, sd = sd(arima2.1.2$residuals))
shapiro.test(arima2.1.2$residuals)
```
Efectivaente, al realizar la prueba de normaildad el p-valor fue menor al nivel de significancia por lo que se rechaza la hipotesis nula de que los residuales provienen de una distribución normal.

## Gráficas de los modelos y la serie
```{r}
plot(l.PM2.5, type = "l", col = "black", lwd = 2, main = "Ajuste del modelo ARMA(2,2)")
lines(fitted(arma2.2), col = "red", lwd = 2)
legend("bottomleft", legend = c("Serie original", "Ajuste ARMA(2,2)"),
       col = c("black", "red"), lwd = 2)
plot(l.PM2.5, type = "l", col = "black", lwd = 2, main = "Ajuste del modelo ARIMA(2,1,2)")
lines(fitted(arima2.1.2), col = "red", lwd = 2)
legend("bottomleft", legend = c("Serie logaritmica", "Ajuste ARIMA(2,1,2)"),
       col = c("black", "red"), lwd = 2)

```
Ambos modelos parecen ajustarse bien a los datos.

# Selección del mejor modelo
Recordando que el modelo ARMA(2,2) obtuvo mejores AIC, y loglik que el modelo ARIMA(2,1,2), y observando que ambos modelos tienen un comportamiento similar en los residuales y que ambos parecen ajustarse bien a los datos, por criterio de parsimonio el mejor modelo es el ARMA(2,2)



