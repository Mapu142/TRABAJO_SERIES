---
title: "CALIDAD_AIRE_ESTACIONALIDAD"
author:
- María Paula Camargo Rincón
- Laura Katherin Martinez Castiblanco
- Yudy Vanessa Puerres Rosero
date: "2025-11-21"
output:
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: sentence
---

```{r}
rm(list=ls())
```

# librerías

```{r message=FALSE, warning=FALSE, show=F}
#install.packages("readxl")
#install.packages("knitr")
#install.packages("forecast")
#install.packages("FinTS")
#install.packages("dplyr")
#install.packages("ggplot2")
#install.packages("lubridate")
#install.packages("zoo")
#install.packages("nortest")
library(readxl) # Para leer el csv
library(knitr) # Para obtener la tabla en el pdf a partir de una tabla en r
library(forecast) # para el lambda de box-cox
library(tseries) # prueba de estacionariedad adf
library(FinTS)
library(dplyr) # para manejo de datos
library(ggplot2) # para gráficas
library(lubridate) # fechas
library(zoo) #imputación de datos faltantes
library(nortest) # para prueba kolmogorov
```

# Descripción de los datos:

## Base de datos

La base de datos utilizada proviene del conjunto de datos público disponible en la plataforma Kaggle ([Rohan Rao, 2020](https://www.kaggle.com/datasets/rohanrao/air-quality-data-in-india)).
Este conjunto fue recopilado originalmente por el Central Pollution Control Board (CPCB**)**, organismo oficial del Gobierno de la India encargado del monitoreo ambiental.

Para este estudio, se utilizó la versión diaria del conjunto de datos, enfocándose exclusivamente en la variable PM2.5 (µg/m³) (partículas en suspensión con diámetro aerodinámico $\leq$ 2.5 µm) registrada en la ciudad de Delhi.
La serie abarca el período comprendido entre el 1 de enero de 2015 y el 6 de diciembre de 2020, con observaciones diarias.

```{r paged.print=TRUE}
aire <- read_excel("Datos_India.xlsx")
knitr::kable(head(aire,10),
             caption = "Primeros 10 datos",
             digits = 4)  # redondea a 4 decimales
```

Además de PM2.5, el conjunto incluye el Índice de Calidad del Aire (AQI) y su clasificación categórica (*AQI_Bucket*), que divide la calidad del aire en seis niveles: *Good*, *Satisfactory*, *Moderate*, *Poor*, *Very Poor* y *Severe*.
Sin embargo, dado que el objetivo del análisis es modelar la dinámica temporal de la concentración de PM2.5, se trabajó únicamente con la variable numérica continua.

```{r warning=FALSE, paged.print=TRUE}
# Convertir 'City' y 'AQI_Bucket' a variables de tipo factor
aire$City <- as.factor(aire$City)
aire$AQI_Bucket <- as.factor(aire$AQI_Bucket)

# Convertir 'Date' a una variable de fecha, especificando el formato
aire$Date <- as.Date(aire$Date, format = "%d/%m/%Y")

summary(aire)

str(aire)
```

## Evaluación de base de datos

```{r}
# Agrupar por fecha y contar el número de registros
daily_counts <- aire %>%
  group_by(Date) %>%
  summarise(count = n())

# Filtrar las fechas que tienen más de un registro
dates_with_duplicates <- daily_counts %>%
  filter(count > 1)

# Mostrar las fechas con registros duplicados
if (nrow(dates_with_duplicates) > 0) {
  cat("Días con más de un valor de PM2.5:\n")
  print(dates_with_duplicates)
} else {
  cat("No hay días con más de un valor de PM2.5\n")
}
# eliminar daily_counts para liberar memoria
rm(daily_counts)
```

El conjunto inicial contiene 2,009 observaciones.
Se identificaron 2 valores faltantes en la variable `PM2.5` y 10 en `AQI_Bucket`.
Dado que el AQI no se utilizará en el modelado, se centró la atención en imputar los valores ausentes de PM2.5.
Se aplicó interpolación lineal mediante la función `na.approx()` del paquete `zoo`, asumiendo que la evolución de la contaminación en el corto plazo no es drástica.

```{r paged.print=TRUE}
aire[!complete.cases(aire), ]
# Usar interpolación lineal para rellenar valores faltantes en 'PM2.5'
# Podemos usar la función na.approx del paquete zoo para la interpolación lineal.
aire$`PM2.5` <- na.approx(aire$`PM2.5`)

# Verificar que no haya más valores faltantes en 'PM2.5'
missing_pm25_after_imputation <- sum(is.na(aire$`PM2.5`))
cat("Número de datos faltantes en 'PM2.5' después de la imputación:", missing_pm25_after_imputation, "\n")
```

Las estadísticas resumen de la serie de PM2.5 revelan una distribución altamente asimétrica hacia la derecha, con una media de 117.104 µg/m³, una mediana de 94.49 µg/m³ y un máximo extremo de 685.36 µg/m³.

```{r paged.print=TRUE}
# Estadísticas descriptivas
summary_stats <- aire %>%
  summarise(
    Media = mean(PM2.5, na.rm = TRUE),
    Mediana = median(PM2.5, na.rm = TRUE),
    Desv_Est = sd(PM2.5, na.rm = TRUE),
    Min = min(PM2.5, na.rm = TRUE),
    Max = max(PM2.5, na.rm = TRUE)
  )

kable(summary_stats, digits = 3, caption = "Estadísticas descriptivas de PM2.5 ")
```

```{r}
library(ggplot2)

ggplot(aire, aes(x = Date, y = PM2.5)) +
  geom_line(color = "steelblue") +
  labs(title = "Serie temporal PM2.5 en Delhi (2015–2020)",
       x = "Fecha", y = "PM2.5 (µg/m³)") +
  theme_minimal()

```

La figura anterior muestra la evolución diaria de los niveles de PM2.5 en Delhi entre enero de 2015 y diciembre de 2020.
Se observa un comportamiento altamente variable, con episodios extremos que superan los 600 µg/m³ e intervalos de disminución temporal, especialmente en algunos meses.

A partir de la visualización se destacan cuatro características importantes:

La serie no presenta una tendencia claramente creciente o decreciente a largo plazo; sin embargo, sí muestra ciclos de aumento y descenso que se repiten cada año.
Se observa una ligera reducción global de la variabilidad, probablemente asociada a medidas de control ambiental o al periodo de confinamiento por COVID-19.

Los valores de PM2.5 fluctúan intensamente, hay episodios extremos \> 500 µg/m³ pero tambien días con valores relativamente bajos \< 50 µg/m³.
Esto justifica el uso de modelos ARIMA/SARIMA, ya que la serie muestra fuerte autocorrelación e irregularidad típica de fenómenos atmosféricos.

```{r}

pm_mensual <- aire %>%
  mutate(mes = format(Date, "%m")) %>%
  group_by(mes) %>%
  summarise(promedio = mean(PM2.5))

pm_mensual

```

```{r}

pm_mensual$mes <- factor(pm_mensual$mes, levels = sprintf("%02d", 1:12))

ggplot(pm_mensual, aes(x = mes, y = promedio, group = 1)) +
  geom_line(color = "blue") +
  geom_point(size = 2) +
  labs(
    title = "Promedio mensual de PM2.5 (2015–2020)",
    x = "Mes",
    y = "PM2.5 promedio (µg/m³)"
  ) +
  theme_minimal()

```

La gráfica anterior muestra el comportamiento promedio mensual del PM2.5 en Delhi durante el periodo 2015–2020.
Se observa una estacionalidad anual muy marcada, con niveles de contaminación que aumentan y disminuyen siguiendo un patrón consistente cada año.

En primer lugar, se identifican valores considerablemente elevados en los meses de diciembre (≈ 173 µg/m³), enero (≈ 162 µg/m³) y noviembre (≈ 160 µg/m³).
Este comportamiento está asociado a condiciones meteorológicas adversas como la inversión térmica, la baja dispersión atmosférica, el aumento en el uso de combustibles y episodios estacionales de contaminación, como la quema de residuos agrícolas y la celebración de Diwali.

Durante la transición hacia el verano, entre los meses de marzo y mayo, se observa una disminución progresiva de los niveles de PM2.5 (alrededor de 100–105 µg/m³), aunque estos aún se mantienen por encima de los estándares recomendados.

Los valores más bajos se presentan entre junio y agosto (≈ 75–90 µg/m³), coincidiendo con la llegada de la temporada de monzones, caracterizada por lluvias intensas que reducen significativamente la concentración de partículas en suspensión.
Posteriormente, en septiembre inicia un ascenso gradual que se intensifica en octubre, mes en el cual los niveles aumentan de forma abrupta (≈ 150 µg/m³), marcando el inicio del nuevo ciclo de contaminación invernal. En conjunto, la gráfica evidencia un ciclo estacional anual fuerte.

```{r}
aire$mes <- factor(format(aire$Date, "%m"), levels = sprintf("%02d", 1:12))

ggplot(aire, aes(x = mes, y = PM2.5)) +
  geom_boxplot(fill =  "darkcyan", color = "darkblue") +
  labs(
    title = "Distribución mensual de PM2.5 (2015–2020)",
    x = "Mes",
    y = "PM2.5 (µg/m³)"
  ) +
  theme_minimal()


```

La figura correspondiente al boxplot mensual permite analizar la variabilidad de los niveles diarios de PM2.5 dentro de cada mes del año.
En términos generales, se identifica un patrón estacional coherente con lo observado en la gráfica del promedio mensual, pero ahora con mayor detalle sobre la dispersión y los valores atípicos.

En enero, noviembre y diciembre se observan las cajas más altas y amplias, lo cual indica que en estos meses no solo aumentan los niveles promedio de PM2.5, sino que además la dispersión es considerablemente mayor, esto sugiere una mayor frecuencia de episodios extremos de contaminación durante el invierno, consistente con condiciones de inversión térmica y aumentos en emisiones, estos meses presentan también numerosos valores atípicos, muchos por encima de los 300–400 µg/m³, reflejando eventos altamente contaminados.

Durante los meses de junio a agosto, correspondientes a la temporada de monzones, las cajas se ubican en niveles mucho más bajos (≈ 70–100 µg/m³), y la dispersión es menor en comparación con los meses de invierno, los outliers son menos frecuentes y menos extremos, lo que confirma que la lluvia y la humedad reducen la presencia de partículas en suspensión.

Los meses de marzo a mayo presentan una dispersión intermedia y medianas alrededor de los 100–120 µg/m³, representando una fase de transición entre los niveles mínimos del monzón y los máximos del invierno.

Finalmente, en octubre se observa un incremento abrupto tanto en la mediana como en la pendiente superior de la caja, lo cual coincide con el final del monzón y el inicio del periodo de emisiones por quema agrícola. Esto confirma la naturaleza progresiva del aumento de PM2.5 previo al invierno.

# Identificación de modelos

La gráfica de la serie de tiempo muestra una variabilidad, con estacionalidad clara (patrones repetidos, que parecieran ser anuales).
Aunque no se observa una tendencia, la varianza no es constante puesto que los picos son más pronunciados en ciertos períodos del año, lo que sugiere heterocedasticidad.

```{r fig.height=4, fig.width=10}
# Creación de la serie temporal
start_date <- min(aire$Date)
end_date <- max(aire$Date)
PM2.5 <- ts(aire$`PM2.5`, 
            start = c(year(start_date), month(start_date), day(start_date)), 
            end = c(year(end_date), month(end_date), day(end_date)), 
            frequency = 365)
PM2.5_zoom <- window(PM2.5, start = c(2016, 1), end = c(2018, 1))

# Configurar dos gráficos en una fila
par(mfrow = c(1, 2))

# Gráfico completo
ts.plot(PM2.5, col = "darkcyan", lwd = 1.5,
        ylab = "PM2.5 promedio diario", xlab = "Tiempo",
        main = "Serie completa")
# Gráfico con zoom
ts.plot(PM2.5_zoom, col = "darkcyan", lwd = 1.5,
        ylab = "PM2.5 promedio diario", xlab = "Tiempo",
        main = "Zoom: 2016-2017")

```

```{r fig.height=6.5, fig.width=10}
# Configurar panel 1x2: izquierda = serie completa, derecha = zoom
par(mfrow = c(2, 2))

## Panel izquierdo: Serie completa
acf(PM2.5, lag.max = 800, main = "ACF - 2 años", col = "darkcyan", lwd = 1) # 800 > 2*365 → muestra más de 2 años
pacf(PM2.5, lag.max = 800, main = "PACF - 2 años", col = "darkcyan", lwd = 1)
## Panel derecho: Serie con zoom (subconjunto)
acf(PM2.5, lag.max = 200, main = "ACF - Zoom (1er año)", col = "darkcyan", lwd = 1)   # ajusta lag.max al tamaño del subconjunto
pacf(PM2.5, lag.max = 50, main = "PACF - Zoom (1/4 de año)", col = "darkcyan", lwd = 1.25)
```

Podemos ver picos altos en los lag $0$, $1$ y $2$ en el ACF, los cuales son decrecientes y hacen referencia a la estacionalidad anual, es decir el lag 1 hace referencia al día 365 (1 año), el lag 2 al día 730 (2 años).

Para evaluar formalmente la estacionariedad en media (la cual segun gráficos parece ser estacionaria), se usa la prueba de Dickey-Fuller (ADF).
El estadístico resultante fue -4.7414 con un p-valor \< 0.01, lo que permite rechazar la hipótesis nula de raíz unitaria.
Por lo tanto, la serie se considera estacionaria.

```{r}
adf.test(PM2.5, alternative = "stationary")
```

Al aplicar la descomposición STL (Seasonal-Trend-Loess) se confirma visualmente lo encontrado anteriormente; El componente estacional exhibe un patrón anual repetitivo, con picos consistentes a finales de año.
Al evaluar la tendencia de la serie, se evidencia como aumentan la cantidad de PM2.5, la cual se reduce considerablemente en lo que parese el periodo de pandemia.

```{r fig.height=6.5, fig.width=10}
# Descomposición STL
plot(stl(PM2.5, s.window = "periodic"), col = "darkcyan", lwd = 1.25)
```

Dada la heterocedasticidad, se evaluo una transformación para estabilizar la varianza.
Se estimó el parámetro de Box-Cox, obteniéndo $\lambda$ $\approx$ 0.257, cercano a cero.
Por lo cual se aplicó la transformación logarítmica.

```{r fig.height=4, fig.width=10}
lambda <- BoxCox.lambda(PM2.5)
lambda

# Transformación logarítmica
l.PM2.5 <- log(PM2.5)
ts.plot(l.PM2.5, col = "darkcyan", lwd = 1.25,
        ylab = "log(PM2.5 promedio diario)",
        main = "Serie transformada logarítmicamente")
```

La serie transformada presenta una varianza más homogénea y mantiene la estacionariedad en media (prueba ADF con p-valor $\approx$ 0.027), sin embargo, a su vez mantiene la estacionalidad anual.

```{r}
adf.test(l.PM2.5,alternative = "stationary")
```

Luego de aplicar la transformación logarítmica a la serie de PM2.5, el test de Dickey–Fuller Aumentado (ADF) arrojó un estadístico de -3.65 con un p-valor de 0.027, lo que indicaría estacionariedad a un nivel de significancia del 5%.
Sin embargo, la inspección de la función de autocorrelación (ACF) revela un decaimiento lento, señal de persistencia temporal y posible estacionalidad anual.

A su vez se observa en la descomposición STL que la estructura estacional anual persiste con patrones cíclicos bien definidos cada año.
Ademas al evaluar los residuales reflejan un comportamiento aleatorio, luego la transformación permite capturar adecuadamente la serie.

```{r fig.height=6.5, fig.width=10}
# Descomposición STL 
plot(stl(l.PM2.5, s.window = "periodic"), col = "darkcyan", lwd = 1.25)
```

Dada la estacionalidad persistente de la serie log-transformada aún no puede considerarse estrictamente estacionaria (decaimiento lento del ACF), y se considera aplicar una diferenciación regular (d = 1) o incluir una componente estacional al modelo.

```{r fig.height=4, fig.width=10}
par(mfrow = c(1, 2))

acf(l.PM2.5, lag.max = 1000, main = "ACF ", col = "darkcyan", lwd = 1)  # decaimiento lento indica que la serie no es estacionaria
pacf(l.PM2.5, lag.max = 50, main = "PACF - Zoom (1/4 de año)", col = "darkcyan", lwd = 1.25)
```

Por lo tanto, se plantea un primer modelo con una diferenciación de primer orden $(1-B)Z_{t}$ con el fin de eliminar la tendencia presente en la serie.
La inspección de la serie transformada muestra oscilaciones alrededor de una media constante, sin tendencias visibles.

```{r fig.height=6.5, fig.width=10, paged.print=TRUE}
d.l.PM2.5 <- diff(l.PM2.5,differences = 1) # Retorno de PM2.5

plot(stl(d.l.PM2.5, s.window = "periodic"), col = "darkcyan", lwd = 1.25)
# ts.plot(d.l.PM2.5, col = "darkcyan", lwd = 1.25,
#         ylab = " difflog(PM2.5 promedio diario)", xlab = "Tiempo",
#         main = "Serie con diff de la transformación logaritmo")
```

La descomposición STL revela que el componente “data” ya no presenta tendencia visible, con oscilaciones centradas alrededor de cero, mientras que el componente “seasonal” mantiene su estructura anual, aunque con amplitud reducida, lo que sugiere que la diferenciación eliminó la tendencia sin afectar significativamente la estacionalidad subyacente.

Asimismo, la función de autocorrelación (ACF) decae rápidamente tras el primer rezago, indicando ausencia de dependencia de largo plazo, mientras que la PACF muestra un patrón más localizado, lo cual es consistente con la presencia de estacionalidad.

```{r fig.height=4, fig.width=10, paged.print=TRUE}
par(mfrow=c(1,2))
acf(d.l.PM2.5,lag.max = 100, col = "darkcyan", lwd = 1.25)
pacf(d.l.PM2.5,lag.max = 100, col = "darkcyan", lwd = 1.25)

```

El test de Dickey–Fuller Aumentado (ADF) arrojó un estadístico de -16.31 con un p-valor \< 0.01, indicando que la serie diferenciada efectivamente es estacionaria.

```{r fig.height=6.5, fig.width=10}
adf.test(d.l.PM2.5,alternative = "stationary")
```

En conjunto, estos resultados validan que la serie transformada y diferenciada cumple con los supuestos de estacionariedad requeridos para la identificación y ajuste de modelos lineales de series temporales.

Por otro lado se quiere comparar con un modelo que tenga en cuenta la estacionalidad y se evalua el modelo diferenciado con respecto a la estacionalidad de la serie con tranformación $\log$, es decir se tiene la siguiente serie $(1-B^{365})Z_{t}$.

Esta serie presenta en su descomposición STL oscilaciones alrededor de cero, sin tendencia aparente en "data", mientras que el componente “seasonal” es notablemente atenuado, indicando que la diferenciación estacional ha eliminado eficazmente el patrón anual subyacente.
El componente de “trend”, aunque suave, muestra una ligera declinación en los últimos años, sugiriendo una posible mejora relativa en los niveles promedio de contaminación tras la remoción de la estacionalidad.

```{r fig.height=6.5, fig.width=10}
ds.l.PM2.5 <- diff(l.PM2.5,lag = 365) # Retorno de PM2.5

plot(stl(ds.l.PM2.5, s.window = "periodic"), col = "darkcyan", lwd = 1.25)
# ts.plot(ds.l.PM2.5, col = "darkcyan", lwd = 1.25,
#         ylab = " diff(log(PM2.5 promedio diario)", xlab = "Tiempo",
#         main = "Serie con diff de la transformación logaritmo")
```

Por otro lado, la prueba de Dickey-Fuller Aumentada arrojó un estadístico de -9.0883 (p-valor \< 0.01), lo que permite rechazar con gran certeza la hipótesis nula de raíz unitaria, confirmando la estacionariedad de la serie diferenciada.

```{r}
adf.test(ds.l.PM2.5,alternative = "stationary")
```

Asimismo, la función de autocorrelación (ACF) presenta rezagos significativos en los primeros valores y en múltiplos de 365, lo cual refleja la persistencia de cierta estructura residual estacional, mientras que la PACF decrece rápidamente, sugiriendo que un modelo SARIMA con componentes autorregresivos y de media móvil podría ser adecuado para capturar la dinámica restante.

```{r fig.height=4, fig.width=10}
par(mfrow=c(1,2))
acf(ds.l.PM2.5,lag.max = 800, col = "darkcyan", lwd = 1)
pacf(ds.l.PM2.5,lag.max = 800, col = "darkcyan", lwd = 1)
```

En conjunto, estos resultados validan que la serie transformada y diferenciada estacionalmente cumple con los supuestos de estacionariedad requeridos para la identificación y ajuste de modelos ARIMA y SARIMA.

# Estimación del modelo

Se procedió a ajustar dos modelos candidatos: un modelo $ARMA(2,2)$ y un $SARIMA(2,0,2)\times (0,1,0)_{365}$ .Sin embargo, dadas las limitaciones computacionales asociadas con la especificación $SARIMA(2,0,2) \times (0,1,0)_{365}$, especialmente por la alta dimensionalidad del operador estacional (periodo = $365$), se optó por emplear la función `auto.arima()` con restricciones que mantuvieran la estructura no estacional dentro del rango propuesto (hasta orden 2 en $AR$ y $MA$) y fijaran el componente estacional a $(0,1,0)$.
Adicionalmente, mas adelante se comprueba que estos dos modelos SARIMA se comportan de similar manera, luego es preferible trabajar con el modelo de menor costo computacional.

```{r}
arma2.2 <- arima(x = l.PM2.5, order = c(2,0,2))
arma2.2
#muy pesado computacionalmente
sarima2.0.2x0.1.0 <- Arima(
  l.PM2.5,
  order = c(2,0,2),
  seasonal = list(order = c(0,1,0), period = 365),
  optim.control = list(maxit = 5)  # límite de iteraciones
  )

#SARIMA con auto.arima optimizado (más inteligente)
sarima_auto <- auto.arima(
  l.PM2.5,
  d = 0,              # Ya aplicamos transformación
  D = 1,              # Diferenciación estacional
  max.p = 2, max.q = 2,
  max.P = 0, max.Q = 0,
  seasonal = TRUE,
  stepwise = TRUE,    # para velocidad
  approximation = TRUE, # para series largas
  trace = TRUE        # Para monitorear progreso
)
sarima_auto
```

En cuanto al modelo $ARMA(2,2)$, este logró un ajuste más preciso en la muestra de entrenamiento, evidenciado por métricas de error inferiores en comparación con el modelo SARIMA estimado.
Sin embargo hay que considerar que aunque pareciera predecir mejor el modelo ARIMA, muy seguramente serría para pronosticos cercanos y no a largo plazo, pues no concidera la estacionariedad.

```{r paged.print=TRUE}
# Obtener métricas de error en la muestra de entrenamiento
acc_arma2.2    <- accuracy(arma2.2)
acc_sarima2.0.2x0.1.0 <- accuracy(sarima2.0.2x0.1.0)
acc_sarima_auto <- accuracy(sarima_auto)
# Crear tabla comparativa
comparacion <- data.frame(
  Modelo = c("ARMA(2,2)", "SARIMA(1,0,2)(0,1,0)[365]", "SARIMA(2,0,2)(0,1,0)[365]"),
  RMSE = c(acc_arma2.2[1, "RMSE"],
           acc_sarima_auto[1, "RMSE"],
           acc_sarima2.0.2x0.1.0[1, "RMSE"]),
  MAE  = c(acc_arma2.2[1, "MAE"],
           acc_sarima_auto[1, "MAE"],
           acc_sarima2.0.2x0.1.0[1, "MAE"]),
  MAPE = c(acc_arma2.2[1, "MAPE"],
           acc_sarima_auto[1, "MAPE"],
           acc_sarima2.0.2x0.1.0[1, "MAPE"])
)

# Mostrar tabla
knitr::kable(comparacion,
             caption = "Comparación de métricas de error en la muestra de entrenamiento",
             digits = 4,
             row.names = FALSE)

```

## Fórmulas estimadas de los modelos

```{r paged.print=TRUE}
# Extraer coeficientes y sus errores estándar
extraer_coeficientes <- function(modelo, nombre) {
  coefs <- coef(modelo)
  se <- sqrt(diag(modelo$var.coef))
  out <- data.frame(
    Modelo = nombre,
    Coeficiente = names(coefs),
    Estimado = round(coefs, 4),
    Error = round(se[match(names(coefs), names(se))], 4),
    stringsAsFactors = FALSE
  )
  return(out)
}

# Crear tabla combinada
tabla_coef <- rbind(
  extraer_coeficientes(arma2.2, "ARMA(2,2)"),
  extraer_coeficientes(sarima_auto, "SARIMA(1,0,2)(0,1,0)[365]")
)

# Mostrar en formato bonito
knitr::kable(tabla_coef, 
             caption = "Coeficientes estimados de los modelos",
             col.names = c("Modelo", "Parámetro", "Estimación", "Error estándar"),
             digits = 4,
             booktabs = TRUE)
```

### Modelo $ARMA(2,2)$

El modelo ARMA(2,2) ajustado a la serie transformada $\log(\text{PM2.5}_t)$ tiene la forma:

$$
\log(\text{PM2.5}_t) = 4.5934 + 1.3806 \cdot \log(\text{PM2.5}_{t-1}) - 0.3876 \cdot \log(\text{PM2.5}_{t-2}) + a_t - 0.5955 \cdot a_{t-1} - 0.2087 \cdot a_{t-2}
$$

donde $a_t$ es el término de error (ruido blanco).

### Modelo $SARIMA(1,0,2) \times (0,1,0)_{365}$

El modelo $SARIMA(1,0,2) \times (0,1,0)_{365}$ ajustado a la misma serie transformada se expresa como:

$$
(1 - B^{365}) \log(\text{PM2.5}_t) = -0.0001 \cdot t + 0.6698 \cdot (1 - B^{365}) \log(\text{PM2.5}_{t-1}) + A_t + 0.0670 \cdot a_{t-1} - 0.1365 \cdot a_{t-2}
$$

o, de forma equivalente en su representación no diferenciada:

$$
\log(\text{PM2.5}_t) = \log(\text{PM2.5}_{t-365}) - 0.0001 \cdot t + 0.6698 \cdot \left( \log(\text{PM2.5}_{t-1}) - \log(\text{PM2.5}_{t-366}) \right) + a_t + 0.0670 \cdot a_{t-1} - 0.1365 \cdot a_{t-2}
$$

# Validación de los modelos

Para garantizar la validez de los modelos ajustados ($ARMA(2,2)$ y $SARIMA(1,0,2) \times (0,1,0)_{365}$) se procedió a evaluar si sus residuales cumplen con los supuestos teóricos de un proceso de ruido blanco: ausencia de autocorrelación, homocedasticidad y distribución aproximadamente normal.

```{r fig.height=4.5, fig.width=10}
# Función para validar residuales de un modelo
check_whiteness <- function(modelo, model_name, period = 365) {
  cat("=== Validación de residuales:", model_name, "===\n")
  resid <- residuals(modelo)
  # Histograma y Q-Q plot
  par(mfrow = c(1, 2))
  qqnorm(resid, main = paste("Q-Q Plot:", model_name))
  qqline(resid, col = "darkcyan")
  
  # ACF y PACF de los residuales (hasta 800 rezagos para ver estacionalidad)
  pacf(resid, lag.max = 800, main = paste("PACF de residuales:", model_name), col = "darkcyan")
  
  par(mfrow = c(1, 1))
  checkresiduals(modelo, col = "darkcyan")
  # Prueba de Ljung-Box: rezagos clave
  # Rezago 20: dependencia general
  lb20 <- Box.test(resid, lag = 20, type = "Ljung-Box")
  # Rezago 365: dependencia estacional anual
  lb365 <- Box.test(resid, lag = 365, type = "Ljung-Box")
  # Rezago 730: dependencia estacional a 2 años
  lb730 <- Box.test(resid, lag = 730, type = "Ljung-Box")
  
  cat("Prueba Ljung-Box (lag=20):  p-valor =", round(lb20$p.value, 4), "\n")
  cat("Prueba Ljung-Box (lag=365): p-valor =", round(lb365$p.value, 4), "\n")
  cat("Prueba Ljung-Box (lag=730): p-valor =", round(lb730$p.value, 4), "\n")
  
  if (lb365$p.value > 0.05) {
    cat("→ No hay evidencia de autocorrelación estacional en los residuales (lag=365).\n")
  } else {
    cat("→ ¡Advertencia! Posible autocorrelación estacional en residuales (lag=365).\n")
  }
}
```

## Modelo $ARMA(2,2)$

Al evaluar los residuales no se encuentran patrones evidentes ni cambios en la varianza.
El histograma muestra una distribución simétrica y centrada en cero, mientras que el gráfico Q-Q confirma una buena aproximación a la normalidad, especialmente en las colas intermedias.

La función de autocorrelación parcial (PACF) de los residuales no presenta picos significativos en los primeros rezagos, lo cual sugiere ausencia de dependencia temporal local.
Además, la prueba de Ljung-Box aplicada en múltiplos del período estacional (lag = 365 y lag = 730) arroja p-valores superiores a 0.05 (p = 0.1211 y p = 0.0201, respectivamente), lo que indica ausencia de autocorrelación estacional significativa en los residuales.

```{r fig.height=4, fig.width=10, paged.print=FALSE}

# Aplicar validación a ambos modelos
check_whiteness(arma2.2, "ARMA(2,2)")
```

## Modelos SARIMA

En este caso es mas evidente que ambos modelos son equivalentes en sus desempeños.
Se tiene un Q-Q plot aceptable a excepción por la concentración en la media dada por la aparente autocorrelación.

La prueba de Ljung-Box aplicada al rezago 365 arroja un p-valor nulo (p $\approx$ 0), lo que implica evidencia estadísticamente significativa de autocorrelación estacional en los residuales.
Esto a pesar de incluir parte estacional en el modelo.

```{r fig.height=4, fig.width=10}

check_whiteness(sarima_auto, "SARIMA(1,0,2)(0,1,0)[365]")
check_whiteness(sarima2.0.2x0.1.0, "SARIMA(2,0,2)(0,1,0)[365]")
```

# Selección del modelo

Para la selección del mejor modelo se procede a evaluar la habilidad predictiva de cada modelo para un año, para evaluar cual capta de mejor manera el comportacmiento a futuro y en particular como predice la estacionalidad.

```{r message=TRUE}
# Definir conjunto de entrenamiento (excluyendo el último año)
train_end <- length(l.PM2.5) - 365
l.PM2.5_train <- window(l.PM2.5, end = time(l.PM2.5)[train_end])
l.PM2.5_test <- window(l.PM2.5, start = time(l.PM2.5)[train_end + 1])

cat("Período de entrenamiento:", start(l.PM2.5_train), "a", end(l.PM2.5_train), "\n")
cat("Período de prueba:", start(l.PM2.5_test), "a", end(l.PM2.5_test), "\n")
cat("Observaciones en prueba:", length(l.PM2.5_test), "\n")
```

## Modelo $ARMA(2,2)$

```{r}
arma2.2_train <- arima(l.PM2.5_train, order = c(2,0,2))
cat("ARMA(2,2) re-estimado - AIC:", arma2.2_train$aic, "\n")

```

```{r}
# Pronóstico ARMA(2,2)
forecast_arma <- forecast(arma2.2_train, h = 365)
cat("Pronóstico ARMA(2,2) - generado\n")
```

```{r fig.height=5, fig.width=10}

# Gráfico 1: ARMA vs Observado
plot(forecast_arma, main = "Pronóstico ARMA(2,2) vs Observado - Último Año",
     ylab = "log(PM2.5)", xlab = "Tiempo")
lines(l.PM2.5_test, col = "red", lwd = 1.25)
legend("topleft", legend = c("Pronóstico", "Intervalo 80%", "Intervalo 95%", "Observado"),
       col = c("blue", "lightblue", "lightgray", "red"), lty = c(1, 1, 1, 1), lwd = c(2, 5, 5, 2), cex = 0.8)
```

## Modelo SARIMA

```{r}
sarima_auto_train <- auto.arima(
  l.PM2.5_train,
  d = 0,
  D = 1,
  max.p = 1, max.q = 2,
  max.P = 0, max.Q = 0,
  seasonal = TRUE,
  stepwise = TRUE,
  approximation = TRUE,
  trace = FALSE
)
cat("SARIMA auto re-estimado - Especificación:", arimaorder(sarima_auto_train), "\n")
cat("SARIMA auto re-estimado - AIC:", sarima_auto_train$aic, "\n")
```

```{r}
# Pronóstico SARIMA auto
forecast_sarima_auto <- forecast(sarima_auto_train, h = 365)
cat("Pronóstico SARIMA auto - generado\n")
```

```{r fig.height=5, fig.width=10}
# Gráfico 2: SARIMA Auto vs Observado
plot(forecast_sarima_auto, main = "Pronóstico SARIMA Auto vs Observado - Último Año",
     ylab = "log(PM2.5)", xlab = "Tiempo")
lines(l.PM2.5_test, col = "red", lwd = 1.5)
legend("topleft", legend = c("Pronóstico", "Intervalo 80%", "Intervalo 95%", "Observado"),
       col = c("blue", "lightblue", "lightgray", "red"), lty = c(1, 1, 1, 1), lwd = c(2, 5, 5, 1), cex = 0.8)
```

## Comparación de modelos

```{r}
# Función para calcular métricas de error
calculate_forecast_metrics <- function(forecast_obj, actual) {
  pred <- as.numeric(forecast_obj$mean)
  errors <- actual - pred
  
  metrics <- c(
    RMSE = sqrt(mean(errors^2, na.rm = TRUE)),
    MAE = mean(abs(errors), na.rm = TRUE),
    MAPE = mean(abs(errors/actual) * 100, na.rm = TRUE),
    MASE = mean(abs(errors)) / mean(abs(diff(actual, lag = 365)), na.rm = TRUE)
  )
  return(metrics)
}

# Calcular métricas para cada modelo
metrics_arma <- calculate_forecast_metrics(forecast_arma, l.PM2.5_test)
metrics_sarima_auto <- calculate_forecast_metrics(forecast_sarima_auto, l.PM2.5_test)

# Crear tabla comparativa
forecast_comparison <- data.frame(
  Modelo = c("ARMA(2,2)", "SARIMA Auto"),
  RMSE = c(metrics_arma["RMSE"], metrics_sarima_auto["RMSE"]),
  MAE = c(metrics_arma["MAE"], metrics_sarima_auto["MAE"]),
  MAPE = c(metrics_arma["MAPE"], metrics_sarima_auto["MAPE"])
)

# Mostrar tabla comparativa
knitr::kable(
  forecast_comparison,
  caption = "Comparación de métricas de error en pronóstico out-of-sample (1 año)",
  digits = 4,
  row.names = FALSE
)
```

Todas las métricas son muy diferentes entre los dos modelos y claramente el modelo SARIMA supera en habilidad predictiva al modelo ARIMA.
Dado que el objetivo de este trabajo es determinar el mejor modelo para pronóstico de la undefined $SARIMA(1,0,2)\times(0,1,0)_{365}.$



# Pronóstico

El pronóstico corresponde al periodo comprendido entre el 7 de diciembre de 2020 y el 6 de diciembre de 2021.

```{r}
library(forecast)

# --- 1. Pronóstico en escala log ---
forecast_log <- forecast(sarima_auto, h = 365)

# --- 2. Convertir el pronóstico a escala original PM2.5 ---
# media pronosticada
forecast_PM25 <- exp(forecast_log$mean)

# intervalos 80% y 95%
lower80 <- exp(forecast_log$lower[,1])
upper80 <- exp(forecast_log$upper[,1])

lower95 <- exp(forecast_log$lower[,2])
upper95 <- exp(forecast_log$upper[,2])

# --- 3. Gráfica en escala original ---
plot(forecast_log, main = "Pronóstico de PM2.5 (Escala original)",
     ylab = "PM2.5 (µg/m³)", xlab = "Tiempo")

lines(forecast_PM25, col = "blue", lwd = 2)
lines(lower80, col = "lightblue", lwd = 2)
lines(upper80, col = "lightblue", lwd = 2)
lines(lower95, col = "gray", lwd = 2)
lines(upper95, col = "gray", lwd = 2)

legend("topleft",
       legend = c("Pronóstico", "80% intervalo", "95% intervalo"),
       col = c("blue", "lightblue", "gray"),
       lty = 1, lwd = 2, cex = 0.8)

```

El pronóstico generado a partir del modelo  $SARIMA(1,0,2)\times(0,1,0)_{365}.$ permite estimar la evolución futura de los niveles de PM2.5 para un año. Los valores pronosticados se presentan en escala original (µg/m³) para facilitar su interpretación.

El patrón proyectado mantiene la estacionalidad anual observada, se espera un incremento significativo en los niveles de PM2.5 entre noviembre y enero, alcanzando valores promedio cercanos a 150–180 µg/m³, con intervalos de pronóstico al 95% que llegan hasta los 220–250 µg/m³. Estos niveles corresponden a categorías de contaminación “Muy Mala” o “Peligrosa”, según estándares internacionales.

Durante los meses de junio, julio y agosto, el modelo prevé una marcada disminución de PM2.5, situándose alrededor de 70–90 µg/m³, consistente con la temporada de monzones en Delhi. A partir de septiembre y octubre, se observa nuevamente un ascenso pronunciado, señalando el comienzo del nuevo ciclo invernal y la reaparición de condiciones atmosféricas adversas.

Los intervalos de pronóstico muestran una mayor amplitud en los meses de máxima contaminación, reflejando la alta variabilidad presente en los episodios extremos de PM2.5. A pesar de ello, la dinámica general proyectada es coherente con el comportamiento histórico, lo que respalda la capacidad del modelo para capturar adecuadamente la estacionalidad y los picos de contaminación característicos de la ciudad.





